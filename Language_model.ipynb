{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6eda034b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries \n",
    "import nltk \n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize, sent_tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fe8204c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input text - to summarize \n",
    "text = \"\"\" In the methods of text representation, text embeddings are commonly used. A dispersed word or character representation in a multidimensional space is called an embedding. Fundamentally, a CNN will be assumed to be able to determine which words are more suitable to the classification task based on local invariance, and to be able to comprehend sentence meaning by combining word embeddings thanks to the compositional property. \n",
    "CNNs aren't designed to learn phrases that completely alter a sentence's meaning, though, if the space between words is greater than the kernel size, since the filter's size is usually restricted to two to seven n-grams. Figurative language, such as that found in ironic, humorous, or metaphorical sentences, presents these linguistic constructions in which one part of the sentence expresses one sentiment and the other the opposite. CNNs have a difficult time capturing these long-distance relationships.\n",
    "CNN configuration for text classification is discussed using two different approaches. One is that, depending on the embeddings' stride size, word embeddings can be utilized for one-dimension convolution by concatenating them. The second is that embeddings can be stacked vertically to calculate a convolution whose width is fixed to the number of embeddings. The convolutional input size for each of these methods needs to remain constant across the dataset.\n",
    "From the training dataset, maximum length of the sentence will become the maximum matrix size. Padding will be included as a result of this restriction. By using padding, it is ensured that every input sentence will have the same dimensions and that the convolution will compute quickly. A vector representing a specific token, typically a vector of zeros is placed inside this padding. Noise is added to the input sentence when inserting a zero-vector padding, and this noise affects how the CNN model is trained.\n",
    "To replace zero-padding, they introduce sentence padding with embedding of words present in the text. As a result, the network is forced to learn long-distance relationships between words as the kernel moves through the word matrix toward the end of the sentence and learns connection between the beginning and the end of the sentence. In this way, semantic-based padding won’t add the CNN input size and also doesn’t represent bottleneck preprocessing of input dataset.\n",
    "Increasing semantic-based padding did not result in a higher training computational cost for a CNN. Because the new embedding vector took up the padding zero vector's space, the memory allocated for the matrix remained constant, even with semantically based padding. Furthermore, there was no benchmarking of the training time of a CNN using the enhanced semantic-based padding. A vector of zeros won't speed up training because the convolutional operation is applied at the kernel level using the parallel capabilities of GPUs.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8a872f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing the text \n",
    "stopWords = set(stopwords.words(\"english\")) \n",
    "words = word_tokenize(text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df833a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a frequency table to keep the \n",
    "# score of each word \n",
    "\n",
    "freqTable = dict() \n",
    "for word in words: \n",
    "\tword = word.lower() \n",
    "\tif word in stopWords: \n",
    "\t\tcontinue\n",
    "\tif word in freqTable: \n",
    "\t\tfreqTable[word] += 1\n",
    "\telse: \n",
    "\t\tfreqTable[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "371ecf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary to keep the score \n",
    "# of each sentence \n",
    "sentences = sent_tokenize(text) \n",
    "sentenceValue = dict() \n",
    "\n",
    "for sentence in sentences: \n",
    "\tfor word, freq in freqTable.items(): \n",
    "\t\tif word in sentence.lower(): \n",
    "\t\t\tif sentence in sentenceValue: \n",
    "\t\t\t\tsentenceValue[sentence] += freq \n",
    "\t\t\telse: \n",
    "\t\t\t\tsentenceValue[sentence] = freq \n",
    "\n",
    "\n",
    "\n",
    "sumValues = 0\n",
    "for sentence in sentenceValue: \n",
    "\tsumValues += sentenceValue[sentence] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3deb8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average value of a sentence from the original text \n",
    "average = int(sumValues / len(sentenceValue)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "220390c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " These can include coronary artery disease with chest pain (angina), heart attack, stroke and narrowing of arteries (atherosclerosis). Too much sugar can injure the walls of the tiny blood vessels (capillaries) that nourish the nerves, especially in the legs. Diabetes may leave you more prone to skin problems, including bacterial and fungal infections. Type 2 diabetes may increase the risk of dementia, such as Alzheimer's disease. Complications in your baby can be caused by gestational diabetes, including:\n",
      "-\tExcess growth of baby\n",
      "-\tLow blood sugar\n",
      "-\tObesity\n",
      "-\tDiabetes type 2\n",
      "-\tDeath\n",
      "\n",
      "Excess growth. Sometimes babies of mothers with gestational diabetes develop low blood sugar (hypoglycemia) shortly after birth. Babies of mothers who have gestational diabetes have a higher risk of developing obesity and type 2 diabetes later in life. Untreated gestational diabetes can lead to a baby's death either before or shortly after birth. Complications in the mother also can be caused by gestational diabetes, including:\n",
      "-\tPreeclampsia. If you had gestational diabetes in one pregnancy, you're more likely to have it again with the next pregnancy.\n"
     ]
    }
   ],
   "source": [
    "# Storing sentences into our summary. \n",
    "summary = '' \n",
    "for sentence in sentences: \n",
    "\tif (sentence in sentenceValue) and (sentenceValue[sentence] > (1.2 * average)): \n",
    "\t\tsummary += \" \" + sentence \n",
    "print(summary) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fa8f1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
